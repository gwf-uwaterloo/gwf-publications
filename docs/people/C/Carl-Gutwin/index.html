<!doctype html><html lang=en-us><head><link rel=preconnect href=https://fonts.googleapis.com><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link href="https://fonts.googleapis.com/css2?family=Open+Sans:wght@700&display=swap" rel=stylesheet><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><script src=https://ajax.googleapis.com/ajax/libs/jquery/3.6.1/jquery.min.js></script><script>$(document).on("change","input[type='checkbox']",function(){const collection=document.getElementById("main").children;for(child of collection)
{if(child.id.startsWith(this.id.slice(-9)))
{this.checked?child.style.display="initial":child.style.display="none";}}});</script><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>Carl Gutwin - GWF Publications</title><meta name=generator content="Hugo 0.68.3"><link href=/gwf-publications/gwficon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/gwf-publications/css/main.min.8976777c0832d068a49d330764e507857027f1efa3b8501cf349b0e2db7410fc.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/gwf-publications/css/academicons.min.css></head><body><header style="z-index:1002;top:0;position:sticky;display:block;box-sizing:border-box;font-family:open sans,helvetica neue,Helvetica,Arial,sans-serif;font-size:16px;line-height:1.5;color:#222;-webkit-tap-highlight-color:transparent;-webkit-text-size-adjust:100%"><div id=navbar-container style="height:54px;width:100%;background:rgba(255,255,255,.95);overflow:hidden;-webkit-box-shadow:rgba(0,0,0,.09)0 1px 0;box-shadow:rgba(0,0,0,.09)0 1px 0;box-sizing:border-box;display:block;font-family:open sans,helvetica neue,Helvetica,Arial,sans-serif;font-size:16px;line-height:1.5;color:#222;-webkit-tap-highlight-color:transparent;-webkit-text-size-adjust:100%"><a href=/gwf-publications/ style="color:#0072bc;text-decoration:none;display:inline-block;height:100%;line-height:54px;border-right:1px solid #e6e6e6;margin-left:6px;padding-right:6px;outline-offset:-4px!important;font-weight:700;background:0 0;box-sizing:border-box;cursor:pointer;font-family:open sans,helvetica neue,Helvetica,Arial,sans-serif;font-size:16px;-webkit-tap-highlight-color:transparent"><img src=/gwf-publications/images/gwf-logo.png alt="ACL Logo" style="margin-right:0;height:54px;padding:6px;width:auto;margin-top:-2px;max-width:100%;vertical-align:middle;border:0;box-sizing:border-box;color:#0072bc;line-height:54px;font-weight:700;cursor:pointer;font-family:open sans,helvetica neue,Helvetica,Arial,sans-serif;font-size:16px;-webkit-tap-highlight-color:transparent;-webkit-text-size-adjust:100%"></a>
<a href=/gwf-publications/ style="text-decoration:none;color:#222!important;display:inline-block;font-size:16px;line-height:54px;font-weight:700;outline-offset:-4px!important;padding:0 6px;margin:0 -6px;background:0 0;box-sizing:border-box;cursor:pointer;font-family:open sans,helvetica neue,Helvetica,Arial,sans-serif;-webkit-tap-highlight-color:transparent;-webkit-text-size-adjust:100%;padding-left:4px">Global Water Futures</a></div></header><div id=main-container class=container><section id=main><h2 id=title><span class=font-weight-normal>Carl</span> <span class=font-weight-bold>Gutwin</span></h2><hr><div class=row><div class=col-lg-9><h4>2020</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://gwf-uwaterloo.github.io/gwf-publications/G20-41002.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-secondary align-middle mr-1" href=/gwf-publications/G20-41002.bib data-toggle=tooltip data-placement=top title="Export to BibTeX">bib
</a><a class="badge badge-info align-middle mr-1" href=#abstract-G20-41002 data-toggle=collapse aria-expanded=false aria-controls=abstract-G20-41002 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/gwf-publications/G20-41002/>Clone Swarm: A Cloud Based Code-Clone Analysis Tool</a></strong><br><a href=/gwf-publications/people/V/Venkat-Bandi/>Venkat Bandi</a>,
<a href=/gwf-publications/people/C/Chanchal-K-Roy/>Chanchal K. Roy</a>,
<a href=/gwf-publications/people/C/Carl-Gutwin/>Carl Gutwin</a><br><a href=/gwf-publications/volumes/G20-41/ class=text-muted>2020 IEEE 14th International Workshop on Software Clones (IWSC)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-G20-41002><div class="card-body p-3 small">A code clone is defined as a pair of similar code fragments within a software system. While code clones are not always harmful, they can have a detrimental effect on the overall quality of a software system due to the propagation of bugs and other maintenance implications. Because of this, software developers need to analyse the code clones that exist in a software system. However, despite the availability of several clone detection systems, the adoption of such tools outside of the clone community remains low. A possible reason for this is the difficulty and complexity involved in setting up and using these tools. In this paper, we present Clone Swarm, a code clone analytics tool that identifies clones in a project and presents the information in an easily accessible manner. Clone Swarm is publicly available and can mine any open-sourced GIT repository. Clone Swarm internally uses NiCad, a popular clone detection tool in the cloud and lets users interactively explore code clones using a web-based interface at multiple granularity levels (Function and Block level). Clone results are visualized in multiple overviews, all the way from a high-level plot down to an individual line by line comparison view of cloned fragments. Also, to facilitate future research in the area of clone detection and analysis, users can directly download the clone detection results for their projects. Clone Swarm is available online at clone-swarm.usask.ca. The source code for Clone Swarm is freely available under the MIT license on GitHub.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://gwf-uwaterloo.github.io/gwf-publications/G20-86001.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-secondary align-middle mr-1" href=/gwf-publications/G20-86001.bib data-toggle=tooltip data-placement=top title="Export to BibTeX">bib
</a><a class="badge badge-info align-middle mr-1" href=#abstract-G20-86001 data-toggle=collapse aria-expanded=false aria-controls=abstract-G20-86001 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/gwf-publications/G20-86001/>Tracing shapes with eyes</a></strong><br><a href=/gwf-publications/people/M/Mohammad-Rakib-Hasan/>Mohammad Rakib Hasan</a>,
<a href=/gwf-publications/people/D/Debajyoti-Mondal/>Debajyoti Mondal</a>,
<a href=/gwf-publications/people/C/Carl-Gutwin/>Carl Gutwin</a><br><a href=/gwf-publications/volumes/G20-86/ class=text-muted>Proceedings of the 11th Augmented Human International Conference</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-G20-86001><div class="card-body p-3 small">Eye tracking systems can provide people with severe motor impairments a way to communicate through gaze-based interactions. Such systems transform a user's gaze input into mouse pointer coordinates that can trigger keystrokes on an on-screen keyboard. However, typing using this approach requires large back-and-forth eye movements, and the required effort depends both on the length of the text and the keyboard layout. Motivated by the idea of sketch-based image search, we explore a gaze-based approach where users draw a shape on a sketchpad using gaze input, and the shape is used to search for similar letters, words, and other predefined controls. The sketch-based approach is area efficient (compared to an on-screen keyboard), allows users to create custom commands, and creates opportunities for gaze-based authentication. Since variation in the drawn shapes makes the search difficult, the system can show a guide (e.g., a 14-segment digital display) on the sketchpad so that users can trace their desired shape. In this paper, we take a first step that investigates the feasibility of the sketch-based approach, by examining how well users can trace a given shape using gaze input. We designed an interface where participants traced a set of given shapes. We then compared the similarity of the drawn and traced shapes. Our study results show the potential of the sketch-based approach: users were able to trace shapes reasonably well using gaze input, even for complex shapes involving three letters; shape tracing accuracy for gaze was better than `free-form' hand drawing. We also report on how different shape complexities influence the time and accuracy of the shape tracing tasks.</div></div><h4>2019</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://gwf-uwaterloo.github.io/gwf-publications/G19-109001.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-secondary align-middle mr-1" href=/gwf-publications/G19-109001.bib data-toggle=tooltip data-placement=top title="Export to BibTeX">bib
</a><a class="badge badge-info align-middle mr-1" href=#abstract-G19-109001 data-toggle=collapse aria-expanded=false aria-controls=abstract-G19-109001 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/gwf-publications/G19-109001/>Peripheral Notifications in Large Displays</a></strong><br><a href=/gwf-publications/people/A/Aristides-Mairena/>Aristides Mairena</a>,
<a href=/gwf-publications/people/C/Carl-Gutwin/>Carl Gutwin</a>,
<a href=/gwf-publications/people/A/Andy-Cockburn/>Andy Cockburn</a><br><a href=/gwf-publications/volumes/G19-109/ class=text-muted>Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-G19-109001><div class="card-body p-3 small">Visual notifications are integral to interactive computing systems. With large displays, however, much of the content is in the user's visual periphery, where human capacity to notice visual effects is diminished. One design strategy for enhancing noticeability is to combine visual features, such as motion and colour. Yet little is known about how feature combinations affect noticeability across the visual field, or about how peripheral noticeability changes when a user's primary task involves the same visual features as the notification. We addressed these questions by conducting two studies. Results of the first study showed that noticeability of feature combinations were approximately equal to the better of the individual features. Results of the second study suggest that there can be interference between the features of primary tasks and the visual features in the notifications. Our findings contribute to a better understanding of how visual features operate when used as peripheral notifications.</div></div><h4>2018</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://gwf-uwaterloo.github.io/gwf-publications/G18-89001.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-secondary align-middle mr-1" href=/gwf-publications/G18-89001.bib data-toggle=tooltip data-placement=top title="Export to BibTeX">bib
</a><a class="badge badge-info align-middle mr-1" href=#abstract-G18-89001 data-toggle=collapse aria-expanded=false aria-controls=abstract-G18-89001 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/gwf-publications/G18-89001/>Improving revisitation in long documents with two-level artificial-landmark scrollbars</a></strong><br><a href=/gwf-publications/people/E/Ehsan-Sotoodeh-Mollashahi/>Ehsan Sotoodeh Mollashahi</a>,
<a href=/gwf-publications/people/M/Md-Sami-Uddin/>Md. Sami Uddin</a>,
<a href=/gwf-publications/people/C/Carl-Gutwin/>Carl Gutwin</a><br><a href=/gwf-publications/volumes/G18-89/ class=text-muted>Proceedings of the 2018 International Conference on Advanced Visual Interfaces</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-G18-89001><div class="card-body p-3 small">Document readers with linear navigation controls do not work well when users need to navigate to previously-visited locations, particularly when documents are long. Existing solutions - bookmarks, search, history, and read wear - are valuable but limited in terms of effort, clutter, and interpretability. In this paper, we investigate artificial landmarks as a way to improve support for revisitation in long documents - inspired by visual augmentations seen in physical books such as coloring on page edges or indents cut into pages. We developed several artificial-landmark visualizations that can represent locations even in documents that are many hundreds of pages long, and tested them in studies where participants visited multiple locations in long documents. Results show that providing two columns of landmark icons led to significantly better performance and user preference. Artificial landmarks provide a new mechanism to build spatial memory of long documents - and can be used either alone or with existing techniques like bookmarks, read wear, and search.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://gwf-uwaterloo.github.io/gwf-publications/G18-99001.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-secondary align-middle mr-1" href=/gwf-publications/G18-99001.bib data-toggle=tooltip data-placement=top title="Export to BibTeX">bib
</a><a class="badge badge-info align-middle mr-1" href=#abstract-G18-99001 data-toggle=collapse aria-expanded=false aria-controls=abstract-G18-99001 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/gwf-publications/G18-99001/>Pointing All Around You</a></strong><br><a href=/gwf-publications/people/J/Julian-Petford/>Julian Petford</a>,
<a href=/gwf-publications/people/M/Miguel-A-Nacenta/>Miguel A. Nacenta</a>,
<a href=/gwf-publications/people/C/Carl-Gutwin/>Carl Gutwin</a><br><a href=/gwf-publications/volumes/G18-99/ class=text-muted>Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-G18-99001><div class="card-body p-3 small">As display environments become larger and more diverse - now often encompassing multiple walls and room surfaces - it is becoming more common that users must find and manipulate digital artifacts not directly in front of them. There is little understanding, however, about what techniques and devices are best for carrying out basic operations above, behind, or to the side of the user. We conducted an empirical study comparing two main techniques that are suitable for full-coverage display environments: mouse-based pointing, and ray-cast 'laser' pointing. Participants completed search and pointing tasks on the walls and ceiling, and we measured completion time, path lengths and perceived effort. Our study showed a strong interaction between performance and target location: when the target position was not known a priori the mouse was fastest for targets on the front wall, but ray-casting was faster for targets behind the user. Our findings provide new empirical evidence that can help designers choose pointing techniques for full-coverage spaces.</div></div></div><div class=col-lg-3><a class="btn btn-lg btn-secondary btn-block mb-2" href="https://www.semanticscholar.org/search?q=Carl+Gutwin" title="Search for 'Carl Gutwin' on Semantic Scholar"><i class="ai ai-semantic-scholar"></i><span class=pl-sm-2>Search</span></a><div class=row><div class="col-12 col-md-6 col-lg-12"><div class=card><h5 class=card-header>Co-authors</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/gwf-publications/people/E/Ehsan-Sotoodeh-Mollashahi/ class=align-middle>Ehsan Sotoodeh Mollashahi</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/gwf-publications/people/M/Md-Sami-Uddin/ class=align-middle>Md. Sami Uddin</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/gwf-publications/people/J/Julian-Petford/ class=align-middle>Julian Petford</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/gwf-publications/people/M/Miguel-A-Nacenta/ class=align-middle>Miguel A. Nacenta</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/gwf-publications/people/A/Aristides-Mairena/ class=align-middle>Aristides Mairena</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class="list-group-item list-group-toggle-btn py-1" data-toggle=collapse data-target=#more-coauthors aria-expanded=false aria-controls=more-coauthors>show all...</li><div class="collapse border-top" id=more-coauthors><li class=list-group-item><a href=/gwf-publications/people/A/Andy-Cockburn/ class=align-middle>Andy Cockburn</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/gwf-publications/people/V/Venkat-Bandi/ class=align-middle>Venkat Bandi</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/gwf-publications/people/C/Chanchal-K-Roy/ class=align-middle>Chanchal K. Roy</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/gwf-publications/people/M/Mohammad-Rakib-Hasan/ class=align-middle>Mohammad Rakib Hasan</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/gwf-publications/people/D/Debajyoti-Mondal/ class=align-middle>Debajyoti Mondal</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li></div></ul></div></div><div class="col-12 col-md-6 col-lg-12"><div class="card my-2 my-md-0 my-lg-2"><h5 class=card-header>Venues</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/gwf-publications/venues/gwf/ class=align-middle>GWF</a><span class="badge badge-secondary align-middle ml-2">5</span></li></ul></div></div></div></div></div></section></div><footer class="bg-gradient-light py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5"><div class=container><p class="text-muted small px-1">Global Water Futures Publications!</p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script><script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script><script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script><script>$(function(){$('[data-toggle="tooltip"]').tooltip();if($("#toggle-all-abstracts")){$("#toggle-all-abstracts").click(function(){var target=$("#toggle-all-abstracts");target.attr("disabled",true);if(target.attr("data-toggle-state")=="hide"){$(".abstract-collapse").collapse('show');target.attr("data-toggle-state","show");}else{$(".abstract-collapse").collapse('hide');target.attr("data-toggle-state","hide");}
target.attr("disabled",false);});$("#toggle-all-abstracts").attr("disabled",false);}})</script></body></html>